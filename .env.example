# ============================================================================
# Application Configuration
# ============================================================================

# Environment Mode
NODE_ENV=development

# ============================================================================
# Logging Configuration
# ============================================================================

# Log Level: error, warn, info, debug (default: info)
LOG_LEVEL=info

# ============================================================================
# LLM Provider Configuration (Powered by Vercel AI SDK)
# ============================================================================

# ============================================================================
# Ollama Configuration
# ============================================================================
OLLAMA_SERVER_URL=http://host.docker.internal:11434
OLLAMA_MODEL=qwen2.5:1.5b

# ============================================================================
# OpenAI Configuration
# ============================================================================
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4o-mini

# ============================================================================
# Anthropic Claude Configuration
# ============================================================================
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# ============================================================================
# AWS Bedrock Configuration
# ============================================================================
# AWS_BEARER_TOKEN_BEDROCK=your_aws_bedrock_bearer_token_here
# AWS_REGION=us-east-1
# BEDROCK_MODEL=anthropic.claude-3-5-sonnet-20241022-v2:0

# ============================================================================
# Microsoft Azure OpenAI Configuration
# ============================================================================
# AZURE_API_KEY=your_azure_api_key_here
# AZURE_RESOURCE_NAME=your_azure_resource_name
# AZURE_BASE_URL=https://theotter-europe.cognitiveservices.azure.com/openai
# AZURE_MODEL=model-router
# AZURE_API_VERSION=2025-01-01-preview

# ============================================================================
# Google Cloud Vertex AI Configuration
# ============================================================================
# Path to your GCP service account JSON credentials file
# GOOGLE_APPLICATION_CREDENTIALS=./credentials/xxxxxxxx-gcp-xxxxxxxx.json
# GCP Project ID (required - AI SDK needs this explicitly)
# GOOGLE_VERTEX_PROJECT=your_gcp_project_id
# GCP Region (optional - defaults to us-central1)
# GOOGLE_VERTEX_LOCATION=us-central1
# Gemini model to use (e.g., gemini-2.0-flash, gemini-1.5-pro, gemini-1.5-flash)
# GCP_MODEL=gemini-1.5-flash

# ============================================================================
# Prisma AIRS API Configuration (Optional)
# ============================================================================

PRISMA_AIRS_API_URL=https://service.api.aisecurity.paloaltonetworks.com
PRISMA_AIRS_API_TOKEN=your_api_token_here
PRISMA_AIRS_PROFILE_ID=your_profile_id_here
PRISMA_AIRS_PROFILE_NAME=your_profile_name
