# ============================================================================
# Application Configuration
# ============================================================================

# Environment Mode
NODE_ENV=development

# Server Port
PORT=3001

# ============================================================================
# Logging Configuration
# ============================================================================

# Log Level: error, warn, info, debug (default: info)
LOG_LEVEL=info

# ============================================================================
# LLM Provider Configuration
# ============================================================================

# LLM Provider Selection: ollama or bedrock
LLM_PROVIDER=ollama

# Ollama Configuration (used when LLM_PROVIDER=ollama)
OLLAMA_SERVER_URL=http://host.docker.internal:11434
COORDINATOR_MODEL=qwen2.5:1.5b
TRANSLATION_MODEL=qwen2.5:1.5b

# AWS Bedrock Configuration (used when LLM_PROVIDER=bedrock)
AWS_BEARER_TOKEN_BEDROCK=your_bedrock_api_key_here
AWS_REGION=us-east-1
BEDROCK_COORDINATOR_MODEL=qwen.qwen3-32b-v1:0
BEDROCK_AGENT_MODEL=mistral.mistral-large-2402-v1:0

# ============================================================================
# Prisma AIRS API Configuration (Optional)
# ============================================================================

PRISMA_AIRS_API_URL=https://service.api.aisecurity.paloaltonetworks.com
PRISMA_AIRS_API_TOKEN=your_api_token_here
PRISMA_AIRS_PROFILE_ID=your_profile_id_here
PRISMA_AIRS_PROFILE_NAME=your_profile_name
