# Prisma AIRS API Configuration
PRISMA_AIRS_API_URL=https://service.api.aisecurity.paloaltonetworks.com
PRISMA_AIRS_API_TOKEN=your_api_token_here
PRISMA_AIRS_PROFILE_ID=your_profile_id_here
PRISMA_AIRS_PROFILE_NAME=your_profile_name

# LLM Provider Selection (ollama or bedrock)
LLM_PROVIDER=ollama

# Ollama Configuration (used when LLM_PROVIDER=ollama)
OLLAMA_SERVER_URL=http://host.docker.internal:11434
COORDINATOR_MODEL=qwen2.5:1.5b
TRANSLATION_MODEL=qwen2.5:1.5b

# AWS Bedrock Configuration (used when LLM_PROVIDER=bedrock)
AWS_REGION=us-east-1
BEDROCK_COORDINATOR_MODEL=qwen.qwen3-32b-v1:0
BEDROCK_AGENT_MODEL=anthropic.claude-3-sonnet-20240229-v1:0

# Server Configuration
PORT=3001