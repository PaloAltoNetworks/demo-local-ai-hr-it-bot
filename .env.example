# ============================================================================
# Application Configuration
# ============================================================================

# Environment Mode
NODE_ENV=development

# Server Port
PORT=3001

# ============================================================================
# Logging Configuration
# ============================================================================

# Log Level: error, warn, info, debug (default: info)
LOG_LEVEL=info

# ============================================================================
# LLM Provider Configuration (Powered by Vercel AI SDK)
# ============================================================================

# LLM Provider Selection: openai, anthropic, aws, azure, gcp, ollama
LLM_PROVIDER=ollama

# ============================================================================
# Ollama Configuration (used when LLM_PROVIDER=ollama)
# ============================================================================
OLLAMA_SERVER_URL=http://host.docker.internal:11434
COORDINATOR_MODEL=qwen2.5:1.5b
TRANSLATION_MODEL=qwen2.5:1.5b

# ============================================================================
# OpenAI Configuration (used when LLM_PROVIDER=openai)
# ============================================================================
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_COORDINATOR_MODEL=gpt-4o-mini

# ============================================================================
# Anthropic Claude Configuration (used when LLM_PROVIDER=anthropic)
# ============================================================================
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_COORDINATOR_MODEL=claude-3-5-sonnet-20241022

# ============================================================================
# AWS Bedrock Configuration (used when LLM_PROVIDER=aws)
# ============================================================================
# AWS_REGION=us-east-1
# BEDROCK_COORDINATOR_MODEL=anthropic.claude-3-5-sonnet-20241022-v2:0

# ============================================================================
# Microsoft Azure OpenAI Configuration (used when LLM_PROVIDER=azure)
# ============================================================================
# AZURE_API_KEY=your_azure_api_key_here
# AZURE_RESOURCE_NAME=your_azure_resource_name
# AZURE_DEPLOYMENT_ID=your_deployment_id
# AZURE_COORDINATOR_MODEL=your_deployment_id

# ============================================================================
# Google Cloud Vertex AI Configuration (used when LLM_PROVIDER=gcp)
# ============================================================================
# GOOGLE_API_KEY=your_google_api_key_here
# GCP_COORDINATOR_MODEL=gemini-1.5-flash

# ============================================================================
# Prisma AIRS API Configuration (Optional)
# ============================================================================

PRISMA_AIRS_API_URL=https://service.api.aisecurity.paloaltonetworks.com
PRISMA_AIRS_API_TOKEN=your_api_token_here
PRISMA_AIRS_PROFILE_ID=your_profile_id_here
PRISMA_AIRS_PROFILE_NAME=your_profile_name
